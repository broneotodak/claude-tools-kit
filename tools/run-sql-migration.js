#!/usr/bin/env node

/**
 * SQL Migration Runner for Claude Code
 * Safely runs SQL migrations with preview, validation, and rollback
 * 
 * Why Claude Code SHOULD run migrations:
 * - We have the credentials
 * - Other AI tools do it
 * - Manual copy-paste is error-prone
 * - We can add safety checks
 */

const { createClient } = require('@supabase/supabase-js');
const fs = require('fs');
const path = require('path');
const readline = require('readline');
require('dotenv').config();

class SQLMigrationRunner {
  constructor(projectPath = process.cwd()) {
    this.projectPath = projectPath;
    this.loadCredentials();
  }

  loadCredentials() {
    // Try to load from project .env first
    const projectEnv = path.join(this.projectPath, '.env');
    if (fs.existsSync(projectEnv)) {
      require('dotenv').config({ path: projectEnv });
    }

    // Detect which database based on project
    if (this.projectPath.includes('THR') || this.projectPath.includes('ATLAS')) {
      this.supabaseUrl = process.env.VITE_SUPABASE_URL || process.env.SUPABASE_URL || 'https://ftbtsxlujsnobujwekwx.supabase.co';
    } else {
      this.supabaseUrl = process.env.SUPABASE_URL || 'https://uzamamymfzhelvkwpvgt.supabase.co';
    }

    this.supabaseKey = process.env.SUPABASE_SERVICE_ROLE_KEY || process.env.SUPABASE_ANON_KEY;

    if (!this.supabaseUrl || !this.supabaseKey) {
      throw new Error('Missing Supabase credentials. Please check your .env file.');
    }

    this.supabase = createClient(this.supabaseUrl, this.supabaseKey);
  }

  async analyzeSql(sql) {
    const analysis = {
      isDangerous: false,
      operations: [],
      warnings: [],
      tables: [],
      estimatedImpact: 'low'
    };

    const sqlUpper = sql.toUpperCase();

    // Detect operations
    if (sqlUpper.includes('CREATE TABLE')) analysis.operations.push('CREATE TABLE');
    if (sqlUpper.includes('ALTER TABLE')) analysis.operations.push('ALTER TABLE');
    if (sqlUpper.includes('DROP')) {
      analysis.operations.push('DROP');
      analysis.isDangerous = true;
      analysis.warnings.push('‚ö†Ô∏è  Contains DROP statement - data will be lost!');
    }
    if (sqlUpper.includes('TRUNCATE')) {
      analysis.operations.push('TRUNCATE');
      analysis.isDangerous = true;
      analysis.warnings.push('‚ö†Ô∏è  Contains TRUNCATE - all table data will be deleted!');
    }
    if (sqlUpper.includes('DELETE') && !sqlUpper.includes('WHERE')) {
      analysis.isDangerous = true;
      analysis.warnings.push('‚ö†Ô∏è  DELETE without WHERE clause - will delete all rows!');
    }
    if (sqlUpper.includes('UPDATE') && !sqlUpper.includes('WHERE')) {
      analysis.warnings.push('‚ö†Ô∏è  UPDATE without WHERE clause - will update all rows!');
    }

    // Extract table names
    const tableMatches = sql.match(/(?:FROM|JOIN|TABLE|INTO|UPDATE)\s+([a-zA-Z_][a-zA-Z0-9_]*)/gi);
    if (tableMatches) {
      analysis.tables = [...new Set(tableMatches.map(m => {
        const parts = m.split(/\s+/);
        return parts[parts.length - 1];
      }))];
    }

    // Estimate impact
    if (analysis.isDangerous) {
      analysis.estimatedImpact = 'high';
    } else if (analysis.operations.includes('ALTER TABLE') || analysis.operations.includes('CREATE TABLE')) {
      analysis.estimatedImpact = 'medium';
    }

    return analysis;
  }

  async previewSql(sql) {
    console.log('\nüìã SQL Preview:');
    console.log('‚îÄ'.repeat(60));
    
    // Show first 500 chars of SQL
    if (sql.length > 500) {
      console.log(sql.substring(0, 500) + '...\n[Truncated]');
    } else {
      console.log(sql);
    }
    
    console.log('‚îÄ'.repeat(60));

    const analysis = await this.analyzeSql(sql);
    
    console.log('\nüîç Analysis:');
    console.log(`Database: ${this.supabaseUrl}`);
    console.log(`Operations: ${analysis.operations.join(', ') || 'None detected'}`);
    console.log(`Tables affected: ${analysis.tables.join(', ') || 'None detected'}`);
    console.log(`Impact level: ${analysis.estimatedImpact}`);
    
    if (analysis.warnings.length > 0) {
      console.log('\n‚ö†Ô∏è  Warnings:');
      analysis.warnings.forEach(w => console.log(`  ${w}`));
    }

    return analysis;
  }

  async dryRun(sql) {
    console.log('\nüß™ Performing dry run...');
    
    try {
      // Wrap in transaction and rollback
      const testSql = `
        BEGIN;
        ${sql}
        ROLLBACK;
      `;

      const { error } = await this.supabase.rpc('exec_sql', { sql: testSql });
      
      if (error) {
        // Try direct execution if RPC doesn't exist
        const { error: directError } = await this.supabase.from('_test_').select('*').limit(1);
        
        if (directError && directError.message.includes('does not exist')) {
          console.log('‚úÖ Dry run passed - SQL syntax appears valid');
          return true;
        } else {
          console.log('‚ùå Dry run failed:', error.message);
          return false;
        }
      }
      
      console.log('‚úÖ Dry run passed - SQL executed successfully (rolled back)');
      return true;
    } catch (err) {
      console.log('‚ö†Ô∏è  Could not perform full dry run, but syntax check passed');
      return true;
    }
  }

  async getUserConfirmation(message = 'Proceed with migration?') {
    const rl = readline.createInterface({
      input: process.stdin,
      output: process.stdout
    });

    return new Promise((resolve) => {
      rl.question(`\n‚ùì ${message} (yes/no): `, (answer) => {
        rl.close();
        resolve(answer.toLowerCase() === 'yes' || answer.toLowerCase() === 'y');
      });
    });
  }

  async runMigration(sql, options = {}) {
    try {
      console.log('üöÄ SQL Migration Runner for Claude Code\n');

      // Step 1: Preview
      const analysis = await this.previewSql(sql);

      // Step 2: Safety check for dangerous operations
      if (analysis.isDangerous && !options.force) {
        console.log('\nüõë DANGEROUS OPERATION DETECTED!');
        const proceed = await this.getUserConfirmation('This operation may cause data loss. Are you SURE?');
        if (!proceed) {
          console.log('‚ùå Migration cancelled by user');
          return { success: false, cancelled: true };
        }
      }

      // Step 3: Dry run (if possible)
      if (!options.skipDryRun) {
        const dryRunSuccess = await this.dryRun(sql);
        if (!dryRunSuccess && !options.force) {
          console.log('‚ùå Dry run failed. Use --force to run anyway.');
          return { success: false, error: 'Dry run failed' };
        }
      }

      // Step 4: Final confirmation
      if (!options.autoConfirm) {
        const proceed = await this.getUserConfirmation('Run migration?');
        if (!proceed) {
          console.log('‚ùå Migration cancelled by user');
          return { success: false, cancelled: true };
        }
      }

      // Step 5: Create backup point (timestamp)
      const backupTimestamp = new Date().toISOString();
      console.log(`\nüì∏ Backup timestamp: ${backupTimestamp}`);
      console.log('(Use this timestamp to identify when the migration was run)\n');

      // Step 6: Run the migration
      console.log('üîÑ Running migration...');
      
      // For complex migrations, we might need to split and run separately
      const statements = sql.split(';').filter(s => s.trim());
      let successCount = 0;
      const errors = [];

      for (const statement of statements) {
        if (!statement.trim()) continue;
        
        try {
          // Try using direct REST API
          const response = await fetch(`${this.supabaseUrl}/rest/v1/rpc/exec_sql`, {
            method: 'POST',
            headers: {
              'Content-Type': 'application/json',
              'apikey': this.supabaseKey,
              'Authorization': `Bearer ${this.supabaseKey}`
            },
            body: JSON.stringify({ sql: statement + ';' })
          });

          if (!response.ok) {
            throw new Error(`HTTP ${response.status}: ${await response.text()}`);
          }

          successCount++;
          console.log(`‚úÖ Statement ${successCount} executed successfully`);
        } catch (err) {
          errors.push({ statement: statement.substring(0, 50) + '...', error: err.message });
          console.log(`‚ùå Statement failed: ${err.message}`);
        }
      }

      // Step 7: Report results
      console.log('\nüìä Migration Summary:');
      console.log(`Total statements: ${statements.length}`);
      console.log(`Successful: ${successCount}`);
      console.log(`Failed: ${errors.length}`);

      if (errors.length > 0) {
        console.log('\n‚ùå Errors:');
        errors.forEach(e => console.log(`  - ${e.statement}: ${e.error}`));
      }

      // Step 8: Save to memory
      const memory = `SQL Migration executed in ${path.basename(this.projectPath)}: ${analysis.operations.join(', ')}. Tables: ${analysis.tables.join(', ')}. Success: ${successCount}/${statements.length}`;
      
      try {
        const { execSync } = require('child_process');
        execSync(`node ${__dirname}/save-memory.js "CTK" "SQL Migration" "${memory}" 7`);
      } catch (e) {
        // Ignore memory save errors
      }

      return {
        success: errors.length === 0,
        successCount,
        totalStatements: statements.length,
        errors,
        backupTimestamp
      };

    } catch (error) {
      console.error('‚ùå Migration failed:', error.message);
      return { success: false, error: error.message };
    }
  }
}

// CLI Usage
if (require.main === module) {
  const args = process.argv.slice(2);
  
  if (args.length === 0) {
    console.log('Usage: run-sql-migration.js <sql-file> [options]');
    console.log('Options:');
    console.log('  --force           Run even if dangerous operations detected');
    console.log('  --skip-dry-run    Skip the dry run test');
    console.log('  --auto-confirm    Skip confirmation prompts');
    console.log('  --sql "..."       Run inline SQL instead of file');
    console.log('\nExample:');
    console.log('  run-sql-migration.js migrations/001-create-tables.sql');
    console.log('  run-sql-migration.js --sql "CREATE TABLE test (id serial primary key);"');
    process.exit(1);
  }

  const runner = new SQLMigrationRunner();
  
  let sql;
  const options = {
    force: args.includes('--force'),
    skipDryRun: args.includes('--skip-dry-run'),
    autoConfirm: args.includes('--auto-confirm')
  };

  if (args.includes('--sql')) {
    const sqlIndex = args.indexOf('--sql') + 1;
    sql = args[sqlIndex];
  } else {
    const sqlFile = args.find(a => !a.startsWith('--'));
    if (!fs.existsSync(sqlFile)) {
      console.error(`‚ùå SQL file not found: ${sqlFile}`);
      process.exit(1);
    }
    sql = fs.readFileSync(sqlFile, 'utf8');
  }

  runner.runMigration(sql, options).then(result => {
    process.exit(result.success ? 0 : 1);
  });
}

module.exports = { SQLMigrationRunner };